# Projeto1_PANDAS-PrevisaoSobreviventesTitanic

# PrevisÃ£o de Sobreviventes do Titanic

## ğŸ“„ DescriÃ§Ã£o do Projeto

Este projeto utiliza o famoso dataset do Titanic para construir e avaliar modelos de Machine Learning com o objetivo de prever se um passageiro sobreviveu ou nÃ£o ao desastre. Foram explorados, prÃ©-processados e modelados os dados utilizando as bibliotecas Scikit-learn e Pandas.

## ğŸ¯ Objetivo

O objetivo principal Ã© comparar o desempenho de dois modelos de classificaÃ§Ã£o distintos:
1.  **RegressÃ£o LogÃ­stica**: Um modelo linear, simples e interpretÃ¡vel.
2.  **Random Forest**: Um modelo de ensemble, mais complexo e robusto.

## ğŸ› ï¸ Ferramentas e Bibliotecas Utilizadas

- Python 3.0
- Pandas
- NumPy
- Scikit-learn
- Matplotlib
- Seaborn
- Jupyter Notebook

## ğŸ“‚ Estrutura dos Arquivos

```
.
â”œâ”€â”€ analise_titanic.ipynb   # Notebook com todo o processo de anÃ¡lise e modelagem
â”œâ”€â”€ train.csv               # Dataset de treino original do Kaggle
â”œâ”€â”€ requirements.txt        # Lista de dependÃªncias para reproduÃ§Ã£o do ambiente
â””â”€â”€ README.md               # DocumentaÃ§Ã£o do projeto
```

## âš™ï¸ Como Executar o Projeto

1.  Clone este repositÃ³rio:
    ```bash
    git clone [https://github.com/SEU_USUARIO/previsao-sobreviventes-titanic.git](https://github.com/SEU_USUARIO/previsao-sobreviventes-titanic.git)
    ```
2.  Navegue atÃ© o diretÃ³rio do projeto:
    ```bash
    cd previsao-sobreviventes-titanic
    ```
3.  Crie um ambiente virtual (recomendado):
    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    ```
4.  Instale as dependÃªncias:
    ```bash
    pip install -r requirements.txt
    ```
5.  Abra o Jupyter Notebook:
    ```bash
    jupyter notebook analise_titanic.ipynb
    ```

## ğŸ“ˆ Resultados e ConclusÃ£o

Ambos os modelos foram treinados e avaliados utilizando mÃ©tricas como AcurÃ¡cia, PrecisÃ£o, Recall e F1-Score.

| Modelo | AcurÃ¡cia | PrecisÃ£o (sobreviveu) | Recall (sobreviveu) |
| ------------------- | -------- | --------------------- | ------------------- |
| RegressÃ£o LogÃ­stica | ~80%     | ~0.76                 | ~0.78               |
| **Random Forest** | **~82%** | **~0.78** | **~0.78** |

**ConclusÃ£o**: O modelo **Random Forest apresentou um desempenho superior**. Isso se deve Ã  sua capacidade de capturar relaÃ§Ãµes nÃ£o-lineares e interaÃ§Ãµes complexas entre as features, algo que a RegressÃ£o LogÃ­stica, por ser um modelo linear, nÃ£o consegue fazer com a mesma eficÃ¡cia.

---
*Desenvolvido por Heitor Giometti*
